{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Works much better on **sequential** data such as financial series, text and audio.\n",
    "\n",
    "#### Motivation\n",
    "* Many supervised learning problems deal with ordered sequences (e.g. predicting stock prices)\n",
    "    * `input`: ordered sequence of past series values\n",
    "    * `output`: ordered sequence of futures series values\n",
    "    \n",
    "**Ressources:**\n",
    "* [academic RNN text generator](http://www.cs.toronto.edu/~ilya/rnn.html)\n",
    "* [twitter bots](http://tweet-generator-alex.herokuapp.com/)\n",
    "* [NanoGenMo](https://github.com/NaNoGenMo/2016)\n",
    "* [Robot Shakespear](https://github.com/genekogan/RobotShakespeare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Recursive Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Ordererd sequence**: a list of values ordered by index `(S1,S2,S3,...SP)`\n",
    "    * index can be time stamp or other orders of sequence\n",
    "    \n",
    "* Many real ordered sequences are a product of some underlying process or processes\n",
    "* But underlying process(es) can be a black box, with no model that explains the data\n",
    "* Instead we broadly model ordered sequences **recursively**:\n",
    "    * use past values in a sequence to predict future ones\n",
    "    * we model future values of a sequence mathematically in terms of it's predecessors\n",
    "\n",
    "* **seed**: initial value(s) of a recursive sequence\n",
    "* **order**: number of elements future values are dependent on\n",
    "* **folded and unfolded view**: ways of thinking about recursivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Screen Shot 2017-08-21 at 08.19.33.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **driver**: drive of a recursive sequence (e.g. stock market data)\n",
    "* **hidden sequence**: the sequence being driven. The data is generated recursively using the driver."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "* given a sequence how do we model it as recursive? so that we can make meaningful predictions?\n",
    "* how can we inject this structural assumption into a supervised learner?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feed Forward Networks\n",
    "Straightforward to implement - reverse engineer recursive mode - and can perform reasonably well in certain circumstancens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Screen Shot 2017-08-21 at 09.38.41.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "x = [1, 3, 5, 7, 9, 11, 13]\n",
    "y = [3, 5, 7, 9, 11, 13, 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f703554e9e8>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1, input_shape=(1,), activation='linear'))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(x, y, epochs=3000, batch_size=3, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.98680735],\n",
       "       [  4.99007607],\n",
       "       [  6.99334431],\n",
       "       [  8.99661255],\n",
       "       [ 10.99988174],\n",
       "       [ 13.00314999],\n",
       "       [ 15.00641823]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 1.00163424]], dtype=float32), array([ 1.98517323], dtype=float32)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Points\n",
    "* Given an ordered sequence we can make a recursive approximation to it:\n",
    "    1. guess the architecture of the recursive formula\n",
    "    2. tune the parameters of that architecture optimally, using the sequence itself\n",
    "\n",
    "* can be used as a **generative model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Screen Shot 2017-08-21 at 09.38.41.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding a relu and increasing the window size\n",
    "![](Screen Shot 2017-08-21 at 11.01.41.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have a **window size** of 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1, input_shape=(2,), activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Our ultimate goal is to model ordered sequences recursively\n",
    "* Approach used here: resolve a recursive formula\n",
    "    1. choose architecture (order, functionality)\n",
    "    2. break recursion into levels\n",
    "    3. window sequence -> input/output pairs\n",
    "    4. minimize loss\n",
    "    5. regressor is generative model\n",
    "\n",
    "* Recursive formula --> recursive sequence (approximation to truth)\n",
    "* Some applications require standard train/ test paradigm (e.g. long-term stock predictions)\n",
    "\n",
    "With Feed Forward Networks we can model recursivity correctly but we loose dependence completely, when we start tuning parameters.\n",
    "* Further levels of recursion are not dependent on earlier levels, as they should be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. RNNs\n",
    "* FFNs fails becaulse levels become independent,\n",
    "    * so we need to enforce greater dependency across levels\n",
    "    \n",
    "We want to enforce consecutive level dependency\n",
    "* RNNs has memory since it is dependent on the previous state, which is dependendent on..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
